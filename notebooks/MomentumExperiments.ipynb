{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nbBfI_8PbVDO"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Hyperparams\n",
    "# training config\n",
    "NUM_EPOCHS = 20\n",
    "LR = 0.001\n",
    "# dataset config\n",
    "batch_size = 64\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "generator=torch.Generator().manual_seed(42) # Can be included for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgyFDQs2bK7t",
    "outputId": "1a37f3db-c13e-40f1-c1c2-177cb3ee0c27"
   },
   "outputs": [],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuGtFcYBaTwL"
   },
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "\n",
    "_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "NUM_CLASSES = 0\n",
    "\n",
    "def getTrainingSet(dataset_name):\n",
    "  if dataset_name == 'CIFAR-10':\n",
    "    NUM_CLASSES=10\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                          download=True, transform=transform_train)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                          download=True, transform=transform_test)\n",
    "    trainset, validset = torch.utils.data.random_split(trainset, \n",
    "                                                      [int(len(trainset)*0.8),len(trainset)- \n",
    "                                                      int(len(trainset)*0.8)], generator=generator)\n",
    "  elif dataset_name == 'STL10':\n",
    "    NUM_CLASSES=10\n",
    "    trainset = torchvision.datasets.STL10(root='./data', split='train',\n",
    "                                          download=True, transform=transform_train)\n",
    "    testset = torchvision.datasets.STL10(root='./data', split='test',\n",
    "                                          download=True, transform=transform_train)\n",
    "    trainset, validset = torch.utils.data.random_split(trainset, \n",
    "                                                      [int(len(trainset)*0.8),len(trainset)- \n",
    "                                                      int(len(trainset)*0.8)], generator=generator)\n",
    "  elif dataset_name == 'Caltech101':\n",
    "    NUM_CLASSES=101\n",
    "#     !gdown https://drive.google.com/uc?id=1DX_XeKHn3yXtZ18DD7qc1wf-Jy5lnhD5\n",
    "#     !unzip -qq '101_ObjectCategories.zip' \n",
    "    PATH = '101_ObjectCategories/'\n",
    "    transform = transforms.Compose(\n",
    "      [transforms.CenterCrop(256),\n",
    "      transforms.Resize((64,64)),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    totalset = torchvision.datasets.ImageFolder(PATH, transform=transform_train)\n",
    "    X, y = zip(*totalset)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.3, \n",
    "                                                      stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, \n",
    "                                                    test_size = 0.5, \n",
    "                                                    stratify=y_val)\n",
    "    trainset, validset, testset = list(zip(X_train, y_train)), list(zip(X_val, y_val)), list(zip(X_test, y_test))\n",
    "\n",
    "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "  validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
    "                                            shuffle=False,num_workers=2)\n",
    "  testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "  return trainloader, testloader, validloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGStyleNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 10, init_weights: bool = True):\n",
    "        super(VGGStyleNet, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(1)\n",
    "        self.maxpool2 = nn.MaxPool2d(2)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*8*8, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self) -> None:\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.maxpool2(F.relu(self.conv1(x)))\n",
    "        out = self.maxpool2(F.relu(self.conv2(out)))\n",
    "        out = F.relu(self.conv3_1(out))\n",
    "        out = self.maxpool(F.relu(self.conv3_2(out)))\n",
    "        out = F.relu(self.conv4_1(out))\n",
    "        out = self.maxpool(F.relu(self.conv4_2(out)))\n",
    "        out = F.relu(self.conv5_1(out))\n",
    "        out = self.maxpool(F.relu(self.conv5_2(out)))\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IM8X5tXRHCFR",
    "outputId": "e1877b0e-a420-4186-fb1d-dbeeb84fa699"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "net = VGGStyleNet()\n",
    "net.to(device)\n",
    "trainloader, testloader, validloader = getTrainingSet(\"Caltech101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BQiF_TPMXH8"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=LR, momentum=0.999, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_validation():\n",
    "    val_loss = 0\n",
    "    total_images = 0\n",
    "    correct_images = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      for batch_index, (images, labels) in enumerate(validloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_images += labels.size(0)\n",
    "        correct_images += predicted.eq(labels).sum().item()\n",
    "    val_accuracy = 100.*correct_images/total_images\n",
    "    return val_loss/(batch_index+1), val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFftkVJfMwgB"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  net.train()\n",
    "  correct_images = 0\n",
    "  total_images = 0\n",
    "  training_loss = 0\n",
    "  for batch_index, (images, labels) in enumerate(tqdm(trainloader)):\n",
    "    optimizer.zero_grad()\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    training_loss += loss.item()\n",
    "    _, predicted = outputs.max(1)\n",
    "    total_images += labels.size(0)\n",
    "    correct_images += predicted.eq(labels).sum().item()\n",
    "  print('Epoch: %d, Loss: %.3f, '\n",
    "              'Accuracy: %.3f%% (%d/%d)' % (epoch, training_loss/(batch_index+1),\n",
    "                                       100.*correct_images/total_images, correct_images, total_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yfxc3akdUDSi"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    test_loss = 0\n",
    "    total_images = 0\n",
    "    correct_images = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      for batch_index, (images, labels) in enumerate(tqdm(testloader)):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_images += labels.size(0)\n",
    "        correct_images += predicted.eq(labels).sum().item()\n",
    "    test_accuracy = 100.*correct_images/total_images\n",
    "    print(\"Loss on Test Set is\", test_loss/(batch_index+1))\n",
    "    print(\"Accuracy on Test Set is\",test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train different models across momentum values\n",
    "momentum_values = [0.999, 0.995, 0.99, 0.9]\n",
    "trainloader, testloader, validloader = getTrainingSet(\"Caltech101\")\n",
    "for v in momentum_values:\n",
    "    net = VGGStyleNet(num_classes=101) # make sure to change for caltech101\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=LR, momentum=v, weight_decay=5e-4, nesterov=True)\n",
    "    model_name = 'vgg_nag'+str(v)\n",
    "    history = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train(epoch)\n",
    "        history.append(test_validation())\n",
    "    torch.save(net, '../models/caltech101/' + model_name + '.pt')\n",
    "    outfile = open('../models/caltech101/' + model_name + '_hist.pt','wb')\n",
    "    pickle.dump(history, outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "Qu4r6wHJVmL4",
    "outputId": "c8013a52-b68a-4578-ca75-7a96bcc44d8b"
   },
   "outputs": [],
   "source": [
    "# train single model\n",
    "model_name = 'vgg_999'\n",
    "history = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  train(epoch)\n",
    "  history.append(test_validation())\n",
    "torch.save(net, '../models/' + model_name + '.pt')\n",
    "outfile = open('../models/' + model_name + '_hist.pt','wb')\n",
    "pickle.dump(history, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "qc_eyO6ihGf9",
    "outputId": "5f2b908a-833f-4614-e914-8a07b0a16708"
   },
   "outputs": [],
   "source": [
    "# load trained model\n",
    "net = torch.load('../models/caltech101/vgg_nag0.99.pt')\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss\n",
    "baseline = pickle.load(open(\"../models/cifar-10/vgg_0_hist.pt\", \"rb\" ))\n",
    "vgg_999 = pickle.load(open(\"../models/cifar-10/vgg_nag0.999_hist.pt\", \"rb\" ))\n",
    "vgg_995 = pickle.load(open(\"../models/cifar-10/vgg_nag0.995_hist.pt\", \"rb\" ))\n",
    "vgg_99 = pickle.load(open(\"../models/cifar-10/vgg_nag0.99_hist.pt\", \"rb\" ))\n",
    "vgg_9 = pickle.load(open(\"../models/cifar-10/vgg_nag0.9_hist.pt\", \"rb\" ))\n",
    "plt.plot([v[0] for v in baseline], '-x', label='baseline')\n",
    "plt.plot([v[0] for v in vgg_999], '-x', label='0.999')\n",
    "plt.plot([v[0] for v in vgg_995], '-x', label='0.995')\n",
    "plt.plot([v[0] for v in vgg_99], '-x', label='0.99')\n",
    "plt.plot([v[0] for v in vgg_9], '-x', label='0.9')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Loss vs. No. of epochs - NAG');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy\n",
    "baseline = pickle.load(open(\"../models/cifar-10/vgg_0_hist.pt\", \"rb\" ))\n",
    "vgg_999 = pickle.load(open(\"../models/cifar-10/vgg_nag0.999_hist.pt\", \"rb\" ))\n",
    "vgg_995 = pickle.load(open(\"../models/cifar-10/vgg_nag0.995_hist.pt\", \"rb\" ))\n",
    "vgg_99 = pickle.load(open(\"../models/cifar-10/vgg_nag0.99_hist.pt\", \"rb\" ))\n",
    "vgg_9 = pickle.load(open(\"../models/cifar-10/vgg_nag0.9_hist.pt\", \"rb\" ))\n",
    "plt.plot([v[1] for v in baseline], '-x', label='baseline')\n",
    "plt.plot([v[1] for v in vgg_999], '-x', label='0.999')\n",
    "plt.plot([v[1] for v in vgg_995], '-x', label='0.995')\n",
    "plt.plot([v[1] for v in vgg_99], '-x', label='0.99')\n",
    "plt.plot([v[1] for v in vgg_9], '-x', label='0.9')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy (Val) vs. No. of epochs - NAG');"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week4-1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
